"""
Syst√®me d'alertes pour les notifications WhatsApp
Alerte les admins en cas de d√©faillance critique du syst√®me de notifications
"""

import logging
from datetime import timedelta
from django.utils import timezone
from django.conf import settings
from django.core.cache import cache
from django.core.mail import send_mail
from django.db.models import Count, Q
from .models import Notification

logger = logging.getLogger(__name__)


class NotificationAlertSystem:
    """
    Syst√®me d'alertes pour surveiller la sant√© des notifications
    """
    
    # Seuils d'alerte
    FAILURE_RATE_THRESHOLD = 50  # % d'√©checs sur une p√©riode
    CRITICAL_FAILURES_THRESHOLD = 20  # Nombre d'√©checs en 1h
    PERMANENT_FAILURES_THRESHOLD = 5  # √âchecs permanents avant alerte
    
    # D√©lais de cooldown pour √©viter spam d'alertes
    ALERT_COOLDOWN_MINUTES = 60  # Attendre 1h entre alertes similaires
    
    @classmethod
    def check_and_alert(cls):
        """
        V√©rifie l'√©tat des notifications et envoie des alertes si n√©cessaire
        """
        try:
            # V√©rifier les √©checs r√©cents
            cls._check_recent_failures()
            
            # V√©rifier les √©checs permanents
            cls._check_permanent_failures()
            
            # V√©rifier le taux global d'√©checs
            cls._check_failure_rate()
            
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification des alertes notifications: {str(e)}")
    
    @classmethod
    def _check_recent_failures(cls):
        """V√©rifie les √©checs r√©cents (derni√®re heure)"""
        one_hour_ago = timezone.now() - timedelta(hours=1)
        
        recent_failures = Notification.objects.filter(
            statut='echec',
            date_creation__gte=one_hour_ago
        ).count()
        
        if recent_failures >= cls.CRITICAL_FAILURES_THRESHOLD:
            # V√©rifier le cooldown
            cache_key = 'notif_alert_recent_failures'
            if not cache.get(cache_key):
                cls._send_alert(
                    title='üö® Alerte: Nombreux √©checs de notifications',
                    message=f"{recent_failures} notifications ont √©chou√© dans la derni√®re heure.\n\n"
                            f"Cela peut indiquer un probl√®me avec l'API WaChap.\n\n"
                            f"Action recommand√©e:\n"
                            f"- V√©rifier l'√©tat de l'API WaChap\n"
                            f"- V√©rifier les logs pour identifier la cause\n"
                            f"- V√©rifier que l'abonnement WaChap est actif",
                    level='critical'
                )
                # D√©finir cooldown
                cache.set(cache_key, True, cls.ALERT_COOLDOWN_MINUTES * 60)
    
    @classmethod
    def _check_permanent_failures(cls):
        """V√©rifie les √©checs permanents r√©cents"""
        one_day_ago = timezone.now() - timedelta(days=1)
        
        permanent_failures = Notification.objects.filter(
            statut='echec_permanent',
            date_creation__gte=one_day_ago
        ).count()
        
        if permanent_failures >= cls.PERMANENT_FAILURES_THRESHOLD:
            cache_key = 'notif_alert_permanent_failures'
            if not cache.get(cache_key):
                # Analyser les types d'erreurs
                error_analysis = cls._analyze_permanent_errors()
                
                cls._send_alert(
                    title='‚ö†Ô∏è Alerte: √âchecs permanents de notifications',
                    message=f"{permanent_failures} notifications sont en √©chec permanent (24h).\n\n"
                            f"Analyse des erreurs:\n{error_analysis}\n\n"
                            f"Action requise:\n"
                            f"- V√©rifier les logs d'erreurs\n"
                            f"- Corriger les probl√®mes identifi√©s\n"
                            f"- Annuler les notifications obsol√®tes via le dashboard",
                    level='warning'
                )
                cache.set(cache_key, True, cls.ALERT_COOLDOWN_MINUTES * 60)
    
    @classmethod
    def _check_failure_rate(cls):
        """V√©rifie le taux global d'√©checs"""
        last_24h = timezone.now() - timedelta(days=1)
        
        total_notifications = Notification.objects.filter(
            date_creation__gte=last_24h
        ).count()
        
        if total_notifications < 10:
            # Pas assez de donn√©es pour calculer un taux significatif
            return
        
        failed_notifications = Notification.objects.filter(
            date_creation__gte=last_24h,
            statut__in=['echec', 'echec_permanent']
        ).count()
        
        failure_rate = (failed_notifications / total_notifications) * 100
        
        if failure_rate >= cls.FAILURE_RATE_THRESHOLD:
            cache_key = 'notif_alert_failure_rate'
            if not cache.get(cache_key):
                cls._send_alert(
                    title='üìâ Alerte: Taux d\'√©chec √©lev√©',
                    message=f"Taux d'√©chec des notifications: {failure_rate:.1f}% (24h)\n\n"
                            f"Total: {total_notifications} | √âchecs: {failed_notifications}\n\n"
                            f"Un taux d'√©chec sup√©rieur √† {cls.FAILURE_RATE_THRESHOLD}% "
                            f"indique un probl√®me syst√®me.\n\n"
                            f"Action recommand√©e:\n"
                            f"- V√©rifier la configuration WaChap\n"
                            f"- V√©rifier la connectivit√© r√©seau\n"
                            f"- Consulter le dashboard de monitoring",
                    level='critical'
                )
                cache.set(cache_key, True, cls.ALERT_COOLDOWN_MINUTES * 60 * 2)  # 2h cooldown
    
    @classmethod
    def _analyze_permanent_errors(cls):
        """Analyse les types d'erreurs permanentes"""
        one_day_ago = timezone.now() - timedelta(days=1)
        
        # Compter les erreurs par type (bas√© sur le contenu du message d'erreur)
        errors = Notification.objects.filter(
            statut='echec_permanent',
            date_creation__gte=one_day_ago
        ).values_list('erreur_envoi', flat=True)
        
        error_types = {}
        for error_msg in errors:
            if not error_msg:
                continue
            
            # Extraire le type d'erreur
            if 'http_401' in error_msg.lower() or 'unauthorized' in error_msg.lower():
                error_types['Autorisation (401/403)'] = error_types.get('Autorisation (401/403)', 0) + 1
            elif 'http_400' in error_msg.lower() or 'invalid' in error_msg.lower():
                error_types['Num√©ro invalide (400)'] = error_types.get('Num√©ro invalide (400)', 0) + 1
            elif 'config' in error_msg.lower():
                error_types['Configuration'] = error_types.get('Configuration', 0) + 1
            else:
                error_types['Autres'] = error_types.get('Autres', 0) + 1
        
        # Formater l'analyse
        if error_types:
            analysis = "\n".join([f"  - {k}: {v}" for k, v in error_types.items()])
        else:
            analysis = "  - Aucune analyse disponible"
        
        return analysis
    
    @classmethod
    def _send_alert(cls, title: str, message: str, level: str = 'warning'):
        """
        Envoie une alerte aux administrateurs
        
        Args:
            title: Titre de l'alerte
            message: Contenu d√©taill√©
            level: 'info', 'warning', 'critical'
        """
        logger.warning(f"ALERTE NOTIFICATION: {title}\n{message}")
        
        # 1. Envoyer par email si configur√©
        if settings.ALERT_EMAIL_ENABLED:
            cls._send_email_alert(title, message)
        
        # 2. Envoyer par WhatsApp si configur√© et critique
        if settings.ALERT_WHATSAPP_ENABLED and level == 'critical':
            cls._send_whatsapp_alert(title, message)
    
    @classmethod
    def _send_email_alert(cls, title: str, message: str):
        """Envoie une alerte par email"""
        try:
            admin_email = settings.ADMIN_EMAIL
            if not admin_email:
                logger.warning("ADMIN_EMAIL non configur√©, impossible d'envoyer l'alerte email")
                return
            
            send_mail(
                subject=f"[TS Air Cargo] {title}",
                message=message,
                from_email=settings.DEFAULT_FROM_EMAIL,
                recipient_list=[admin_email],
                fail_silently=False,
            )
            logger.info(f"‚úÖ Alerte email envoy√©e √† {admin_email}")
        except Exception as e:
            logger.error(f"Erreur envoi alerte email: {str(e)}")
    
    @classmethod
    def _send_whatsapp_alert(cls, title: str, message: str):
        """Envoie une alerte par WhatsApp"""
        try:
            admin_phone = settings.ADMIN_PHONE
            if not admin_phone:
                logger.warning("ADMIN_PHONE non configur√©, impossible d'envoyer l'alerte WhatsApp")
                return
            
            from .wachap_service import wachap_service
            
            alert_message = f"üö® {title}\n\n{message}\n\n‚è∞ {timezone.now().strftime('%d/%m/%Y %H:%M')}"
            
            success, result, msg_id = wachap_service.send_message_with_type(
                phone=admin_phone,
                message=alert_message,
                message_type='alert',
                sender_role='system'
            )
            
            if success:
                logger.info(f"‚úÖ Alerte WhatsApp envoy√©e √† {admin_phone}")
            else:
                logger.error(f"‚ùå √âchec envoi alerte WhatsApp: {result}")
                
        except Exception as e:
            logger.error(f"Erreur envoi alerte WhatsApp: {str(e)}")


def check_notification_health():
    """
    Fonction utilitaire pour v√©rifier l'√©tat de sant√© des notifications
    Peut √™tre appel√©e par une t√¢che Celery ou une commande Django
    """
    NotificationAlertSystem.check_and_alert()
